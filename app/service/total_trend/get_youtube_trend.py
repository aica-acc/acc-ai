# %%
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError
from datetime import datetime, timezone, timedelta
from dotenv import load_dotenv
import datetime
load_dotenv()
import os


# %%
YOUTUBE_API_KEY = os.getenv("YOUTUBE_API_KEY")

# %%
YOUTUBE_API_SERVICE_NAME = 'youtube'
YOUTUBE_API_SERVICE_VERSION = 'v3'
youtube = build(YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_SERVICE_VERSION, developerKey = YOUTUBE_API_KEY)

# %%

# ì„¤ì •
TARGET_COUNT = 30


# ğŸ”¹ ìˆí¼: í¬ë¦¬ìŠ¤ë§ˆìŠ¤ ê¸°ì¤€ 2ê°œì›” ì „ ~ í¬ë¦¬ìŠ¤ë§ˆìŠ¤
#   ë‚˜ì¤‘ì—ëŠ” ì´ ë¶€ë¶„ì„ DBì—ì„œ ê°€ì ¸ì˜¨ ì¶•ì œ ì‹œì‘ì¼ë¡œ ë°”ê¾¸ë©´ ë¨

now = datetime.datetime.now(timezone.utc)

# Long (1ê°œì›”)
long_start_dt = now - timedelta(days=30)
long_end_dt = now

LONG_PUBLISHED_AFTER = long_start_dt.strftime("%Y-%m-%dT%H:%M:%SZ")
LONG_PUBLISHED_BEFORE = long_end_dt.strftime("%Y-%m-%dT%H:%M:%SZ")

# Short (2ê°œì›”)
short_start_dt = now - timedelta(days=60)
short_end_dt = now

SHORT_PUBLISHED_AFTER = short_start_dt.strftime("%Y-%m-%dT%H:%M:%SZ")
SHORT_PUBLISHED_BEFORE = short_end_dt.strftime("%Y-%m-%dT%H:%M:%SZ")

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DATA_DIR = os.path.abspath(os.path.join(BASE_DIR, "../../data"))

os.makedirs(DATA_DIR, exist_ok=True)

LONG_OUTPUT_PATH = os.path.join(DATA_DIR, "youtube_long_result.txt")
SHORT_OUTPUT_PATH = os.path.join(DATA_DIR, "youtube_short_result.txt")


# %%
import datetime
import os

TARGET_COUNT = 30


def has_hangul(s: str) -> bool:
    return any('ê°€' <= ch <= 'í£' for ch in (s or ""))


def fetch_and_print_non_shorts(youtube, keyword):
    results = []

    def search_by_duration(dur):
        return youtube.search().list(
            q=keyword,
            part="snippet",
            type="video",
            order="relevance",
            regionCode="KR",
            relevanceLanguage="ko",
            publishedAfter=LONG_PUBLISHED_AFTER,
            publishedBefore=LONG_PUBLISHED_BEFORE,
            videoDuration=dur,  # medium: 4~20ë¶„, long: 20ë¶„~
            maxResults=50
        ).execute().get("items", [])

    # 1) medium + long ì˜ìƒ í•©ì¹˜ê¸°
    items = search_by_duration("medium") + search_by_duration("long")

    # 2) í•œêµ­ì–´ ì±„ë„ë§Œ ë‚¨ê¸°ê¸°
    items = [it for it in items if has_hangul(it["snippet"]["channelTitle"])]

    # 3) ë¹„ë””ì˜¤ ID ì¤‘ë³µ ì œê±°
    seen_ids, video_ids = set(), []
    for it in items:
        vid = it["id"]["videoId"]
        if vid not in seen_ids:
            seen_ids.add(vid)
            video_ids.append(vid)

    if not video_ids:
        print("ë¡±í¼: ì¡°ê±´ì— ë§ëŠ” ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤.")
        return []

    # 4) ìƒì„¸ ì •ë³´ ì¡°íšŒ
    videos = youtube.videos().list(
        part="snippet,statistics,contentDetails",
        id=",".join(video_ids[:50])
    ).execute().get("items", [])

    # 5) ì¡°íšŒìˆ˜ ê¸°ì¤€ ì •ë ¬ + ì±„ë„ ì¤‘ë³µ ì œê±°
    videos_norm = []
    for v in videos:
        stats = v.get("statistics", {})
        views = int(stats.get("viewCount", 0))
        videos_norm.append({
            "id": v["id"],
            "title": v["snippet"]["title"],
            "channel_id": v["snippet"]["channelId"],
            "channel_title": v["snippet"]["channelTitle"],
            "description": v["snippet"].get("description", "").strip(),
            "views": views
        })

    videos_norm.sort(key=lambda x: x["views"], reverse=True)

    seen_channels = set()
    selected = []
    for v in videos_norm:
        if v["channel_id"] in seen_channels:
            continue
        seen_channels.add(v["channel_id"])
        selected.append(v)
        if len(selected) >= TARGET_COUNT:
            break

    # 6) ì¶œë ¥ ë§Œë“¤ê¸°
    for v in selected:
        url = f"https://www.youtube.com/watch?v={v['id']}"
        desc = v["description"].replace("\n", " ").strip()  # í•œ ì¤„ë¡œ ì •ë¦¬

        record = (
            f"URL: {url}\n"
            f"ì œëª©: {v['title']}\n"
            f"ì±„ë„: {v['channel_title']}\n"
            f"ì¡°íšŒìˆ˜: {v['views']}\n"
            f"ì„¤ëª…: {desc or 'ì—†ìŒ'}\n"
        )
        results.append(record)

    return results


def save_to_long_file(texts, output_path):
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    with open(output_path, "w", encoding="utf-8") as f:
        f.write("\n".join(texts))





# %%

# ì„¤ì •
TARGET_COUNT = 30

def has_hangul(s: str) -> bool:
    return any('ê°€' <= ch <= 'í£' for ch in (s or ""))


def fetch_and_print_shorts(youtube, keyword):
    results = []

    # ğŸ”¹ ì‡¼ì¸ (4ë¶„ ë¯¸ë§Œ) ê²€ìƒ‰ â€” ì¶•ì œ ì‹œì‘ì¼ ê¸°ì¤€ 2ê°œì›” ìœˆë„ìš°
    search = youtube.search().list(
        q=keyword,
        part="snippet",
        type="video",
        order="viewCount",
        regionCode="KR",
        relevanceLanguage="ko",
        publishedAfter=SHORT_PUBLISHED_AFTER,   # â† ë„¤ê°€ ì´ë¯¸ ì„ ì–¸í•´ë‘” ë‚ ì§œ
        publishedBefore=SHORT_PUBLISHED_BEFORE, # â† ë„¤ê°€ ì´ë¯¸ ì„ ì–¸í•´ë‘” ë‚ ì§œ
        videoDuration="short",
        maxResults=50
    ).execute()

    items = search.get("items", [])

    # ğŸ”¹ í•œêµ­ì–´ ì±„ë„ë§Œ í•„í„°ë§
    items = [it for it in items if has_hangul(it["snippet"]["channelTitle"])]

    # video ID ìˆ˜ì§‘
    video_ids = [it["id"]["videoId"] for it in items]
    if not video_ids:
        print("ìˆí¼: ì¡°ê±´ì— ë§ëŠ” ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤.")
        return []

    # ğŸ”¹ ìƒì„¸ ì •ë³´ ì¡°íšŒ
    videos = youtube.videos().list(
        part="snippet,statistics,contentDetails",
        id=",".join(video_ids[:50])
    ).execute().get("items", [])

    # ğŸ”¹ ì¡°íšŒìˆ˜ ì •ë ¬ + ì±„ë„ë‹¹ í•œ ê°œë§Œ ì„ íƒ
    videos_norm = []
    for v in videos:
        stats = v.get("statistics", {})
        views = int(stats.get("viewCount", 0))

        videos_norm.append({
            "id": v["id"],
            "title": v["snippet"]["title"],
            "channel_id": v["snippet"]["channelId"],
            "channel_title": v["snippet"]["channelTitle"],
            "description": v["snippet"].get("description", "").strip(),
            "views": views
        })

    videos_norm.sort(key=lambda x: x["views"], reverse=True)

    # ì±„ë„ ì¤‘ë³µ ì œê±°
    seen_channels = set()
    selected = []

    for v in videos_norm:
        if v["channel_id"] in seen_channels:
            continue
        seen_channels.add(v["channel_id"])
        selected.append(v)
        if len(selected) >= TARGET_COUNT:
            break

    # ğŸ”¹ ê²°ê³¼ ë ˆì½”ë“œ êµ¬ì„± (ì„¤ëª… ê¸°ë°˜)
    for v in selected:
        url = f"https://www.youtube.com/watch?v={v['id']}"
        desc = v["description"].replace("\n", " ").strip()

        record = (
            f"URL: {url}\n"
            f"ì œëª©: {v['title']}\n"
            f"ì±„ë„: {v['channel_title']}\n"
            f"ì¡°íšŒìˆ˜: {v['views']}\n"
            f"ì„¤ëª…: {desc or 'ì—†ìŒ'}\n"
        )

        results.append(record)

    return results


def save_to_short_file(texts, output_path):
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    with open(output_path, "w", encoding="utf-8") as f:
        f.write("\n".join(texts))



def run_youtube_search(keyword: str):
    """ìœ íŠœë¸Œ ê²€ìƒ‰ ì‹¤í–‰ â†’ long/short íŒŒì¼ ìƒì„±"""

    # 1) ìˆí¼
    short_texts = fetch_and_print_shorts(youtube, keyword)
    save_to_short_file(short_texts, SHORT_OUTPUT_PATH)

    # 2) ë¡±í¼
    long_texts = fetch_and_print_non_shorts(youtube, keyword)
    save_to_long_file(long_texts, LONG_OUTPUT_PATH)

    print("ğŸ“Œ YouTube ê²€ìƒ‰ ì™„ë£Œ (íŒŒì¼ ì €ì¥ ì™„ë£Œ)")