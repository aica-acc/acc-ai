import os
import json
import requests
import datetime
from dotenv import load_dotenv
from openai import OpenAI
from pydantic import BaseModel
from typing import List


load_dotenv()

NAVER_CLIENT_ID = os.getenv("NAVER_CLIENT_ID")
NAVER_CLIENT_SECRET = os.getenv("NAVER_CLIENT_SECRET")


# ================================================================
# 1) LLM í‚¤ì›Œë“œ í™•ì¥
# ================================================================
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=OPENAI_API_KEY)

class KeywordList(BaseModel):
    keywords: List[str]

def expand_keywords_with_llm(keyword: str, festival_title: str, festival_start_date: str) -> List[str]:
    prompt = f"""
    ë©”ì¸ í‚¤ì›Œë“œ: "{keyword}"
    ì¶•ì œëª…: "{festival_title}"
    ì¶•ì œ ì‹œì‘ì¼: "{festival_start_date}"

    ìœ„ì˜ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ, **ê²€ìƒ‰ íŠ¸ë Œë“œ ë¶„ì„ì— ì‚¬ìš©í•  ì—°ê´€ í‚¤ì›Œë“œ 5ê°œ**ë¥¼ ìƒì„±í•˜ì„¸ìš”.
    ë‹¨ì–´ëŠ” í•œë‹¨ì–´ë¡œë§Œ ìƒì„±í•˜ê³  ëŒ€ì¤‘ì ì¸ í‚¤ì›Œë“œë¥¼ ìƒì„±í•˜ì‹œì˜¤. google trensì— ê²€ìƒ‰ë  ë§Œí•œ í‚¤ì›Œë“œë¥¼ 
    ì‚¬ìš©í•´ì•¼í•©ë‹ˆë‹¤ ë˜í•œ ì²«ë²ˆì¬ í‚¤ì›Œë“œëŠ” ë°˜ë“œì‹œ ë©”ì¸í‚¤ì›Œë“œë¥¼ ë„£ìœ¼ì„¸ì˜¤ 
    ex) > [í¬ë¦¬ìŠ¤ë§ˆìŠ¤, ì‚°íƒ€, íŠ¸ë¦¬, ì—°ë§, ëˆˆ]
    ë°˜ë“œì‹œ 5ê°œì˜ ë¬¸ìì—´ì„ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.
    """

    res = client.chat.completions.parse(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": "í‚¤ì›Œë“œ í™•ì¥ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
            {"role": "user", "content": prompt}
        ],
        response_format=KeywordList  # ğŸ”¥ êµ¬ì¡° ê°•ì œ!
    )

    parsed: KeywordList = res.choices[0].message.parsed
    return parsed.keywords


# ================================================================
# 2) NAVER DATALAB â€“ 1ë…„ì¹˜ ê²€ìƒ‰ëŸ‰ ë¶„ì„
# ================================================================
def get_naver_datalab_1year(keyword: str, festival_title: str, festival_start_date: str):
    """
    ë„¤ì´ë²„ DataLab 1ë…„ì¹˜ ê²€ìƒ‰ëŸ‰ (ì£¼ ë‹¨ìœ„).
    3ê°œ íŒŒë¼ë¯¸í„° ëª¨ë‘ ë°˜ì˜ëœ ë²„ì „.
    """
    print(f"\n[NaverDataLab] 1ë…„ ë¶„ì„ ì‹œì‘: {keyword}, {festival_title}, {festival_start_date}")

    # -----------------------------
    # 1) LLM ê¸°ë°˜ í‚¤ì›Œë“œ í™•ì¥
    # -----------------------------
    expanded_keywords = expand_keywords_with_llm(keyword, festival_title, festival_start_date)

    url = "https://openapi.naver.com/v1/datalab/search"

    today = datetime.date.today()
    one_year_ago = today - datetime.timedelta(days=360)

    # -----------------------------
    # 2) DataLab Request Body
    # -----------------------------
    body = {
        "startDate": one_year_ago.strftime("%Y-%m-%d"),
        "endDate": today.strftime("%Y-%m-%d"),
        "timeUnit": "week",
        "keywordGroups": [
            {
                "groupName": keyword,
                "keywords": expanded_keywords
            }
        ]
    }

    json_bytes = json.dumps(body, ensure_ascii=False).encode("utf-8")

    headers = {
        "X-Naver-Client-Id": NAVER_CLIENT_ID,
        "X-Naver-Client-Secret": NAVER_CLIENT_SECRET,
        "Content-Type": "application/json; charset=utf-8"
    }

    # -----------------------------
    # 3) Request â†’ Response
    # -----------------------------
    try:
        res = requests.post(url, headers=headers, data=json_bytes, timeout=120)
        res.encoding = "utf-8"

        data = res.json()

        # ë„¤ì´ë²„ API ì—ëŸ¬ í•¸ë“¤ë§
        if "error" in data or "errorCode" in data:
            return {"error": data}

        # ì£¼ê°„ íŠ¸ë Œë“œ ë°ì´í„° ë³€í™˜
        weekly_data = []
        for item in data["results"][0]["data"]:
            weekly_data.append({
                "period": item["period"],
                "ratio": item["ratio"]
            })

        print("âœ” Naver DataLab 1ë…„ ë¶„ì„ ì™„ë£Œ")

        # ìµœì¢… ë°˜í™˜ êµ¬ì¡°
        return {
            "naver_weekly": weekly_data,
        }

    except Exception as e:
        return {"error": f"Naver DataLab ì˜¤ë¥˜: {e}"}





