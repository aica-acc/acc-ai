# app/service/poster/make_poster_video.py

import os
import time
import base64
import json
import io
import shutil
from pathlib import Path
from typing import Any, Dict, Optional, Tuple

import requests
from dotenv import load_dotenv
from google import genai
from google.genai import types
from openai import OpenAI
from PIL import Image
import subprocess

load_dotenv()

# --------------------------------------------------
# ê³µí†µ ì„¤ì •
# --------------------------------------------------
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
...
FRONT_PROJECT_ROOT = os.getenv("FRONT_PROJECT_ROOT")
...
PROMOTION_CODE = "M000001"  # ê³ ì •ê°’

load_dotenv()

# --------------------------------------------------
# ê³µí†µ ì„¤ì •
# --------------------------------------------------

PROJECT_ROOT = os.getenv("PROJECT_ROOT")
if not PROJECT_ROOT:
    raise ValueError("PROJECT_ROOT ê°€ .envì— ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
PROJECT_ROOT = Path(PROJECT_ROOT).resolve()

# ì¸íŠ¸ë¡œ ìë§‰ìš© í•œê¸€ í°íŠ¸ (ì˜ˆ: app/fonts/Jalnan2TTF.ttf)
INTRO_FONT_PATH = PROJECT_ROOT / "app" / "fonts" / "Jalnan2TTF.ttf"
if not INTRO_FONT_PATH.exists():
    raise FileNotFoundError(f"ì¸íŠ¸ë¡œ ìë§‰ìš© í°íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {INTRO_FONT_PATH}")

GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
if not GEMINI_API_KEY:
    raise ValueError("GEMINI_API_KEY ê°€ .envì— ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")

FRONT_PROJECT_ROOT = os.getenv("FRONT_PROJECT_ROOT")
if not FRONT_PROJECT_ROOT:
    raise ValueError("FRONT_PROJECT_ROOT ê°€ .envì— ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")


veo_client = genai.Client(api_key=GEMINI_API_KEY)
openai_client = OpenAI()
VEO_MODEL = "veo-3.1-generate-preview"


# --------------------------------------------------
# Veo í—¬í¼ (ê¸°ì¡´ ë¡œì§ ê·¸ëŒ€ë¡œ ìœ ì§€)
# --------------------------------------------------
def wait_for_operation(operation):
    """ë¹„ë™ê¸° ì‘ì—…ì´ ì™„ë£Œë  ë•Œê¹Œì§€ ê¸°ë‹¤ë¦¬ëŠ” í—¬í¼ í•¨ìˆ˜"""
    while not operation.done:
        print("â³ ë¹„ë””ì˜¤ ìƒì„± ëŒ€ê¸° ì¤‘... (10ì´ˆ í›„ ì¬í™•ì¸)")
        time.sleep(10)
        operation = veo_client.operations.get(operation)

    if operation.error:
        print(f"âŒ ë¹„ë””ì˜¤ ìƒì„± ì‹¤íŒ¨: {operation.error}")
        return None
    else:
        video_result = operation.result.generated_videos[0]
        video_uri = video_result.video.uri
        print(f"âœ… ë¹„ë””ì˜¤ ìƒì„± ì™„ë£Œ! ê²°ê³¼ URI: {video_uri}")
        return video_result


def download_video(video_file, output_filename: str) -> Optional[Path]:
    """
    requests ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¹„ë””ì˜¤ URIì—ì„œ ì§ì ‘ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.
    """
    DOWNLOAD_DIR = Path("generated_videos")
    DOWNLOAD_DIR.mkdir(exist_ok=True)

    output_path = DOWNLOAD_DIR / output_filename
    video_uri = video_file.video.uri

    download_url = f"{video_uri}&key={GEMINI_API_KEY}" if "key=" not in video_uri else video_uri

    try:
        response = requests.get(download_url, stream=True)
        response.raise_for_status()

        with open(output_path, "wb") as f:
            for chunk in response.iter_content(chunk_size=8192):
                f.write(chunk)

        print(f"â¬‡ï¸ ë¹„ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {output_path.resolve()}")
        return output_path
    except Exception as e:
        print(f"âŒ ë¹„ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ (requests ì˜¤ë¥˜): {e}")
        return None


def _read_and_encode_image(image_path: str) -> types.Image:
    """ë¡œì»¬ ì´ë¯¸ì§€ë¥¼ ì½ì–´ Base64ë¡œ ì¸ì½”ë”©í•˜ê³  types.Image ê°ì²´ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
    image_path = Path(image_path)
    if not image_path.exists():
        raise FileNotFoundError(f"ì´ë¯¸ì§€ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {image_path}")

    mime_type = "image/jpeg"
    if image_path.suffix.lower() == ".png":
        mime_type = "image/png"

    with open(image_path, "rb") as f:
        image_bytes = f.read()

    base64_encoded_data = base64.b64encode(image_bytes).decode("utf-8")

    return types.Image(
        image_bytes=base64_encoded_data,
        mime_type=mime_type,
    )


def generate_image_to_video(
    prompt: str,
    start_image_path: str,
    end_image_path: str = None,
    download_name: str = "image_to_video.mp4",
) -> Tuple[Optional[Any], Optional[Path]]:
    """
    Veo 3.1ì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ê¸°ë°˜ ë¹„ë””ì˜¤ë¥¼ ìƒì„±í•˜ê³  ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.
    """
    print(f"\n--- 1. Image to Video ì‹œì‘ (í”„ë¡¬í”„íŠ¸: {prompt[:60]}...) ---")

    try:
        start_frame_image = _read_and_encode_image(start_image_path)
        print(f"âœ… ì‹œì‘ ì´ë¯¸ì§€ Base64 ì¸ì½”ë”© ì™„ë£Œ: {start_image_path}")

        last_frame_image = None
        if end_image_path:
            last_frame_image = _read_and_encode_image(end_image_path)
            print(f"âœ… ë ì´ë¯¸ì§€ Base64 ì¸ì½”ë”© ì™„ë£Œ: {end_image_path}")
    except FileNotFoundError as e:
        print(f"âŒ íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None, None
    except Exception as e:
        print(f"âŒ ì´ë¯¸ì§€ ì¸ì½”ë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None, None

    config_params = {}
    if last_frame_image:
        config_params["last_frame"] = last_frame_image

    video_config = types.GenerateVideosConfig(**config_params) if config_params else None

    operation = veo_client.models.generate_videos(
        model=VEO_MODEL,
        prompt=prompt,
        image=start_frame_image,
        config=video_config,
    )

    result_video = wait_for_operation(operation)

    download_path = None
    if result_video:
        download_path = download_video(result_video, download_name)

    return result_video, download_path


def extend_video(
    existing_video,
    extension_prompt: str,
    duration_s: int = 8,
    download_name: str = "extended_video.mp4",
) -> Tuple[Optional[Any], Optional[Path]]:
    """
    ê¸°ì¡´ Veo ë¹„ë””ì˜¤ë¥¼ í™•ì¥í•˜ì—¬ ìƒˆë¡œìš´ í´ë¦½ì„ ìƒì„±í•˜ê³  ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.
    """
    if not existing_video:
        print("âŒ í™•ì¥í•  ê¸°ì¡´ ë¹„ë””ì˜¤ê°€ ì—†ìŠµë‹ˆë‹¤. ì´ì „ ë‹¨ê³„ì˜ ë¹„ë””ì˜¤ ê°ì²´ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        return None, None

    print(f"\n--- 3. Extension (ë¹„ë””ì˜¤ í™•ì¥) ì‹œì‘, ê¸¸ì´: {duration_s}s ---")
    video_uri = existing_video.video.uri
    print(f"ê¸°ì¡´ ë¹„ë””ì˜¤ URI: {video_uri}")
    print(f"í™•ì¥ í”„ë¡¬í”„íŠ¸: {extension_prompt[:80]}...")

    video_config = types.GenerateVideosConfig()

    operation = veo_client.models.generate_videos(
        model=VEO_MODEL,
        prompt=extension_prompt,
        video=existing_video.video,
        config=video_config,
    )

    result_video = wait_for_operation(operation)

    download_path = None
    if result_video:
        download_path = download_video(result_video, download_name)

    return result_video, download_path


def concatenate_videos(input_paths: list[Path], output_filename: str) -> Optional[Path]:
    """
    FFmpegì„ ì‚¬ìš©í•˜ì—¬ ì—¬ëŸ¬ ë¹„ë””ì˜¤ íŒŒì¼ì„ ìˆœì„œëŒ€ë¡œ ì´ì–´ ë¶™ì…ë‹ˆë‹¤.
    """
    print(f"\n--- 4. FFmpegìœ¼ë¡œ ë¹„ë””ì˜¤ ì—°ê²° ì‹œì‘ ---")

    if not input_paths:
        print("âŒ ì—°ê²°í•  ì…ë ¥ íŒŒì¼ ê²½ë¡œê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None

    DOWNLOAD_DIR = Path("generated_videos")
    output_path = DOWNLOAD_DIR / output_filename

    list_file_path = DOWNLOAD_DIR / "file_list.txt"
    with open(list_file_path, "w", encoding="utf-8") as f:
        for path in input_paths:
            f.write(f"file '{path.name}'\n")

    ffmpeg_command = [
        "ffmpeg",
        "-f",
        "concat",
        "-safe",
        "0",
        "-i",
        str(list_file_path),
        "-c",
        "copy",
        "-y",
        str(output_path),
    ]

    try:
        subprocess.run(ffmpeg_command, check=True, capture_output=True, text=True)
        print(f"âœ… ë¹„ë””ì˜¤ ì—°ê²° ì™„ë£Œ: {output_path.resolve()}")
        os.remove(list_file_path)
        return output_path
    except FileNotFoundError:
        print("âŒ ì˜¤ë¥˜: 'ffmpeg' ëª…ë ¹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. FFmpeg PATH ì„¤ì • í™•ì¸ í•„ìš”.")
    except subprocess.CalledProcessError as e:
        print(f"âŒ FFmpeg ì‹¤í–‰ ì˜¤ë¥˜: {e.stderr}")
    except Exception as e:
        print(f"âŒ ì—°ê²° ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ ë°œìƒ: {e}")

    if list_file_path.exists():
        os.remove(list_file_path)
    return None



# --------------------------------------------------
# FFmpeg / ì¸íŠ¸ë¡œ ê´€ë ¨ í—¬í¼
# --------------------------------------------------

def ffmpeg_escape_text(s: str) -> str:
    """
    ffmpeg drawtextìš© í…ìŠ¤íŠ¸ escape í—¬í¼.
    - \, :, ' ì •ë„ë§Œ ì²˜ë¦¬
    """
    return (
        s.replace("\\", "\\\\")  # ì—­ìŠ¬ë˜ì‹œ â†’ \\
         .replace(":", "\\:")    # ì½œë¡  â†’ \:
         .replace("'", "\\'")    # ì‘ì€ë”°ì˜´í‘œ â†’ \'
    )


def ffmpeg_escape_font_path(path: str) -> str:
    """
    drawtext fontfileìš© ê²½ë¡œ escape:
    - ë°±ìŠ¬ë˜ì‹œ â†’ \\
    - ì½œë¡  â†’ \:
    """
    p = path.replace("\\", "\\\\")
    p = p.replace(":", "\\:")
    return p


def get_video_resolution(input_video: str, fallback=(1920, 1080)) -> tuple[int, int]:
    """
    ffprobeë¡œ (width, height) ê°€ì ¸ì˜¤ë˜,
    ì‹¤íŒ¨í•˜ë©´ fallback í•´ìƒë„(ê¸°ë³¸ 1920x1080)ë¥¼ ë¦¬í„´.
    """
    cmd = [
        "ffprobe",
        "-v", "error",
        "-select_streams", "v:0",
        "-show_entries", "stream=width,height",
        "-of", "json",
        input_video,
    ]
    proc = subprocess.run(
        cmd,
        capture_output=True,
        text=True,
        encoding="utf-8",
        errors="ignore",
    )

    if proc.returncode != 0:
        print("âš ï¸ ffprobe ì‹¤íŒ¨, fallback í•´ìƒë„ ì‚¬ìš©:", fallback)
        print("ffprobe stderr:")
        print(proc.stderr)
        return fallback

    info = json.loads(proc.stdout)
    stream = info["streams"][0]
    return int(stream["width"]), int(stream["height"])


def create_black_intro_with_text(
    output_video: str,
    width: int,
    height: int,
    festival_name_ko: str,
    festival_period_ko: str,
    font_path: str,
    duration: float = 2.0,
    fps: int = 30,
    fontsize_title: int = 56,
    fontsize_period: int = 40,
) -> Path:
    """
    ê²€ì • ë°°ê²½ ìœ„ì— ì¶•ì œëª…/ê¸°ê°„ ìë§‰ 2ì¤„ë§Œ ìˆëŠ” ì¸íŠ¸ë¡œ ì˜ìƒ ìƒì„±.
    """
    out_path = Path(output_video)
    out_path.parent.mkdir(parents=True, exist_ok=True)

    # í…ìŠ¤íŠ¸ / í°íŠ¸ escape (add_intro_captionì—ì„œ ì“°ë˜ ë°©ì‹ ì¬ì‚¬ìš©)
    fontfile = ffmpeg_escape_font_path(font_path)
    title_text = ffmpeg_escape_text(festival_name_ko)
    period_text = ffmpeg_escape_text(festival_period_ko)

    drawtext = (
        "drawtext="
        f"fontfile='{fontfile}':"
        f"text='{title_text}':"
        f"fontsize={fontsize_title}:"
        "fontcolor=white:"
        "box=1:boxcolor=black@0.5:boxborderw=20:"
        "x=(w-text_w)/2:"
        "y=(h/2)-50"
        ","
        "drawtext="
        f"fontfile='{fontfile}':"
        f"text='{period_text}':"
        f"fontsize={fontsize_period}:"
        "fontcolor=white:"
        "box=1:boxcolor=black@0.5:boxborderw=16:"
        "x=(w-text_w)/2:"
        "y=(h/2)+30"
    )

    cmd = [
        "ffmpeg",
        "-f", "lavfi",
        "-i", f"color=c=black:s={width}x{height}:d={duration}:r={fps}",
        "-vf", drawtext,
        "-c:v", "libx264",
        "-pix_fmt", "yuv420p",
        "-y",
        str(out_path),
    ]

    print("â–¶ ffmpeg (intro):")
    print(" ".join(cmd))
    print("  raw font_path =", font_path)
    print("  fontfile     =", fontfile)

    try:
        completed = subprocess.run(
            cmd,
            check=True,
            capture_output=True,
            text=True,
            encoding="utf-8",
            errors="ignore",
        )
        if completed.stderr:
            print("ffmpeg intro stderr (ê²½ê³ /ë¡œê·¸):")
            print(completed.stderr)
    except subprocess.CalledProcessError as e:
        print("âŒ ffmpeg intro ìƒì„± ì‹¤íŒ¨")
        print("stdout:")
        print(e.stdout)
        print("stderr:")
        print(e.stderr)
        raise

    return out_path


def concat_intro_and_main(
    intro_video: str,
    main_video: str,
    output_video: str,
) -> Path:
    """
    ì¸íŠ¸ë¡œ ì˜ìƒ(ë¬´ìŒ) + ë³¸í¸ ì˜ìƒ ì„ í•˜ë‚˜ë¡œ ì´ì–´ë¶™ì´ê¸°.
    - ë¹„ë””ì˜¤ 2ê°œ concat
    - ì˜¤ë””ì˜¤ëŠ” ë³¸í¸(ë‘ ë²ˆì§¸ ì…ë ¥) ê²ƒì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©
    """
    intro_path = Path(intro_video)
    main_path = Path(main_video)
    out_path = Path(output_video)
    out_path.parent.mkdir(parents=True, exist_ok=True)

    if not intro_path.exists():
        raise FileNotFoundError(f"intro ì—†ìŒ: {intro_path}")
    if not main_path.exists():
        raise FileNotFoundError(f"main ì—†ìŒ: {main_path}")

    cmd = [
        "ffmpeg",
        "-i", str(intro_path),
        "-i", str(main_path),
        "-filter_complex", "[0:v][1:v]concat=n=2:v=1:a=0[v]",
        "-map", "[v]",
        "-map", "1:a?",   # ë³¸í¸ì— ì˜¤ë””ì˜¤ ìˆìœ¼ë©´ ë³µì‚¬, ì—†ìœ¼ë©´ ë¬´ì‹œ
        "-c:v", "libx264",
        "-c:a", "copy",
        "-pix_fmt", "yuv420p",
        "-y",
        str(out_path),
    ]

    print("â–¶ ffmpeg (concat intro+main):")
    print(" ".join(cmd))

    try:
        completed = subprocess.run(
            cmd,
            check=True,
            capture_output=True,
            text=True,
            encoding="utf-8",
            errors="ignore",
        )
        if completed.stderr:
            print("ffmpeg concat stderr (ê²½ê³ /ë¡œê·¸):")
            print(completed.stderr)
    except subprocess.CalledProcessError as e:
        print("âŒ ffmpeg concat ì‹¤íŒ¨")
        print("stdout:")
        print(e.stdout)
        print("stderr:")
        print(e.stderr)
        raise

    return out_path

# --------------------------------------------------
# LLM: í¬ìŠ¤í„° ê¸°ë°˜ Veo í”„ë¡¬í”„íŠ¸ ìƒì„±
# --------------------------------------------------

VIDEO_SYSTEM_PROMPT = """
You are a professional festival promo-video prompt designer for Google Veo 3.

## Role
Your job is to look at:
- one FESTIVAL POSTER IMAGE, and
- basic FESTIVAL METADATA (name, period, location, concept),

and then generate TWO English prompts for a Veo-based video workflow:

- `segment_1_prompt`: 0â€“8 seconds, image-to-video from the poster
- `segment_2_prompt`: 8â€“15 seconds, extension from the end of segment 1

These two prompts will be used sequentially with Veo's image-to-video
and video-extension features, so the motion and camera must connect
perfectly between segment 1 and segment 2.

---

## Absolute rules

1. This is a **festival promotional video**, not an abstract motion test.
   - The overall feeling must be festive, welcoming, and celebratory.
   - Motions and actions should match the festival theme
     (flowers / spring / mud / lights / snow / ocean, etc.),
     but only if visually compatible with the poster.

2. Use ONLY what is visible or strongly implied in the poster.
   - Colors, shapes, silhouettes, textures, background world, lighting.
   - Do NOT invent random locations, characters, props, or scenes
     that conflict with the poster.

3. Text rules:
   - NEVER generate Korean text inside the prompts.
   - If on-screen text is used in the video, it must be English only.
   - On-screen English text should appear preferably at the very end
     (e.g., last 2 seconds of segment 2).

4. Camera behavior:
   - The viewer must feel like they are being **pulled into the world**
     of the poster, not just watching a flat zoom.
   - You are allowed to reference **After Effects-style** motion design,
     such as:
       - After Effects-style white flash + radial zoom transition,
       - Cinematic 3D parallax camera dive,
       - Portal warp zoom emphasizing depth, not 2D scaling,
       - Momentum-based zoom curve like a professional motion template,
       - Camera passing through a glowing portal or circular gate.
   - However, these must still be visually compatible with the poster
     (e.g., use existing circles, arches, depth cues).

---

## Timing & structure requirements

You MUST format the prompts in this exact narrative structure
and time breakdown.

### 1) `segment_1_prompt` (0â€“8 seconds)

The text MUST start like:

`Generate an 8-second motion teaser from this festival poster.`

Then define two sub-phases with time labels and bullet points:

`0â€“5s (Poster World Entry):`
- Describe how the camera is pulled into the world (3D dive, parallax, etc.).
- Emphasize depth, not flat 2D scaling.
- You may mention:
  - After Effects-style white flash + radial zoom,
  - light convergence into the focal area,
  - portal-like entry if visually justified by the poster.
- Use only elements that exist in the poster (lights, rings, trees, silhouettes, etc.).

`5â€“8s (Poster World Awakens):`
- Camera holds at a stable portal-entry / world-entry distance.
- World elements that exist in the poster begin animated motion:
  - lights flicker or flow,
  - trees or objects shimmer or glow,
  - silhouettes do small, playful micro-motions (no full dance choreography
    unless the poster clearly implies dancing),
  - subtle particles or atmosphere that match the poster (sparkles, dust, snow, etc.).
- No random crowd dancing or music-sync assumptions.
- No extra objects or text added.

### 2) `segment_2_prompt` (8â€“15 seconds)

The text MUST start like:

`Extend teaser to 15 seconds.`

Then define two sub-phases with time labels and bullet points:

`8â€“13s (Poster World Continues):`
- Seamlessly continue the motion from segment 1
  (same rings, lights, silhouettes, environment).
- Camera remains absolutely steady, keeping the posterâ€™s implied perspective.
- Build anticipation by:
  - gradually intensifying glow, motion, or atmosphere,
  - but never breaking the visual logic of the original poster.

`13â€“15s (Reveal FINAL TITLE ):`
- Use a clear, natural action from a main character or silhouette
  (e.g., central figure doing a welcoming gesture) **only if such a figure exists**.
- A 3D text appears in English only, such as:
  - `FESTIVAL COMING SOON`
  - `JOIN THE CELEBRATION`
- The text  behavior can include:
  - emerging from the focal point / portal,
  - slight 3D rotation and motion-momentum easing,
  - a short white-flash burst (0.2â€“0.5s) at the moment of reveal.
- Final 0.3â€“0.5s:
  - text stabilizes at a readable size,
  - holds a subtle 3D tilt (about 6â€“10 degrees),
  - all motion calms down (no extra animation after landing).

---

## Output format (VERY IMPORTANT)

You must return ONLY JSON of the following form:

{
  "segment_1_prompt": "<full English prompt for the first 0â€“8 seconds, following the structure above>",
  "segment_2_prompt": "<full English prompt for 8â€“15 seconds, following the structure above>"
}

- Do NOT include Korean in any field.
- Do NOT wrap the JSON in backticks or markdown fences.
"""


def _encode_image_to_small_data_url(image_path: str, max_size: int = 256, quality: int = 60) -> str:
    """
    í¬ìŠ¤í„° ì´ë¯¸ì§€ë¥¼ Visionìš©ìœ¼ë¡œë§Œ ì“¸ ì‘ì€ ì¸ë„¤ì¼ë¡œ ì¤„ì—¬ì„œ
    data:image/jpeg;base64,... í˜•íƒœë¡œ ë³€í™˜ (TPM ë°©ì§€ìš©).
    """
    p = Path(image_path)
    if not p.exists():
        raise FileNotFoundError(f"í¬ìŠ¤í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {image_path}")

    img = Image.open(p).convert("RGB")
    img.thumbnail((max_size, max_size), Image.LANCZOS)

    buf = io.BytesIO()
    img.save(buf, format="JPEG", quality=quality, optimize=True)
    buf.seek(0)
    b64 = base64.b64encode(buf.read()).decode("utf-8")
    return f"data:image/jpeg;base64,{b64}"


def generate_poster_video_prompts(
    image_path: str,
    festival_name_ko: str,
    festival_period_ko: str,
    festival_location_ko: str,
    concept_description: str,
) -> Dict[str, str]:
    """
    í¬ìŠ¤í„° + ë©”íƒ€ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ Veoìš© segment_1, segment_2 í”„ë¡¬í”„íŠ¸ ìƒì„±
    """
    print("ğŸš€ í¬ìŠ¤í„° ì˜ìƒ í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹œì‘")

    data_url = _encode_image_to_small_data_url(image_path)

    meta_json = json.dumps(
        {
            "festival_name_ko": festival_name_ko,
            "festival_period_ko": festival_period_ko,
            "festival_location_ko": festival_location_ko,
            "concept_description": concept_description,
        },
        ensure_ascii=False,
    )

    user_text = (
        "You will receive FESTIVAL METADATA (in JSON) and a POSTER IMAGE.\n"
        "Use both to design segment_1_prompt and segment_2_prompt as Veo-ready prompts.\n\n"
        "Do NOT include Korean in any field."
        f"Festival metadata JSON:\n{meta_json}"
    )

    resp = openai_client.chat.completions.create(
        model="gpt-4o",
        response_format={"type": "json_object"},
        messages=[
            {"role": "system", "content": VIDEO_SYSTEM_PROMPT},
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": user_text},
                    {"type": "image_url", "image_url": {"url": data_url}},
                ],
            },
        ],
    )

    data = json.loads(resp.choices[0].message.content)
    return data


# --------------------------------------------------
# URL/ìƒëŒ€ê²½ë¡œ â†’ ì‹¤ì œ íŒŒì¼ ê²½ë¡œ ë³€í™˜
# --------------------------------------------------

def _resolve_poster_path_from_url(poster_image_url: str, project_id: str | int) -> Path:
    """
    poster_image_url ì´
    - http ë¡œ ì‹œì‘í•˜ë©´: ë‹¤ìš´ë¡œë“œí•´ì„œ ì„ì‹œ íŒŒì¼ë¡œ ì‚¬ìš©
    - / ë¡œ ì‹œì‘í•˜ê±°ë‚˜ data/... í˜•íƒœë©´: FRONT_PROJECT_ROOT/public ê¸°ì¤€ ìƒëŒ€ê²½ë¡œë¡œ ì‚¬ìš©
    """
    # http(s) URL ì¸ ê²½ìš° â†’ ì„ì‹œ ë‹¤ìš´ë¡œë“œ
    if poster_image_url.startswith("http://") or poster_image_url.startswith("https://"):
        tmp_dir = Path("generated_videos")
        tmp_dir.mkdir(exist_ok=True)
        tmp_path = tmp_dir / f"poster_input_{project_id}.png"

        print(f"ğŸŒ ì›ê²© í¬ìŠ¤í„° ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ: {poster_image_url}")
        resp = requests.get(poster_image_url, stream=True)
        resp.raise_for_status()
        with open(tmp_path, "wb") as f:
            for chunk in resp.iter_content(chunk_size=8192):
                f.write(chunk)
        return tmp_path

    # ë¡œì»¬ ê²½ë¡œ (í”„ë¡ íŠ¸ public ê¸°ì¤€ ìƒëŒ€ê²½ë¡œë¼ê³  ê°€ì •)
    front_root = Path(FRONT_PROJECT_ROOT)
    public_root = front_root / "public"

    # poster_image_url ì´ "/data/..." ì´ê±°ë‚˜ "data/..." ì¸ ì¼€ì´ìŠ¤
    rel = poster_image_url.lstrip("/")  # ë§¨ ì• / ì œê±°
    poster_path = public_root / rel
    return poster_path


# --------------------------------------------------
# ë©”ì¸ ì—”íŠ¸ë¦¬: run_poster_video_to_editor
# --------------------------------------------------

def run_poster_video_to_editor(
    *,
    festival_name_ko: str,
    festival_period_ko: str,
    festival_location_ko: str,
    project_id: int | str,
    poster_image_url: str,
    concept_description: str,
) -> Dict[str, Any]:
    """
    ìš°ë¦¬ê°€ ì•½ì†í•œ ì…ë ¥ë§Œ ë°›ëŠ” ì—”íŠ¸ë¦¬ í•¨ìˆ˜.

    íŒŒì´í”„ë¼ì¸:
    1) poster_image_url â†’ ì‹¤ì œ í¬ìŠ¤í„° ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ê³„ì‚°
    2) LLMìœ¼ë¡œ Veo í”„ë¡¬í”„íŠ¸ 2ê°œ ìƒì„±
    3) Veoë¡œ 8ì´ˆ + í™•ì¥ 7ì´ˆ ì˜ìƒ ìƒì„±
    4) FFmpegìœ¼ë¡œ 15ì´ˆ í•©ì¹˜ê¸°
    5) FRONT_PROJECT_ROOT/public/data/promotion/M000001/{project_id}/video/poster_video.mp4 ì €ì¥
    6) DB ì €ì¥ìš© dict 4ê°œ í•„ë“œ ë°˜í™˜
    """
    pNo = str(project_id)

    # 1. í¬ìŠ¤í„° ì´ë¯¸ì§€ ì‹¤ì œ ê²½ë¡œ
    start_image_path = _resolve_poster_path_from_url(poster_image_url, pNo)
    if not start_image_path.exists():
        raise FileNotFoundError(f"í¬ìŠ¤í„° ì´ë¯¸ì§€ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {start_image_path}")

    # 2. LLM í”„ë¡¬í”„íŠ¸ ìƒì„±
    prompts = generate_poster_video_prompts(
        image_path=str(start_image_path),
        festival_name_ko=festival_name_ko,
        festival_period_ko=festival_period_ko,
        festival_location_ko=festival_location_ko,
        concept_description=concept_description,
    )

    segment_1 = prompts.get("segment_1_prompt", "")
    segment_2 = prompts.get("segment_2_prompt", "")

    if not segment_1 or not segment_2:
        raise ValueError("LLMì´ segment_1_prompt ë˜ëŠ” segment_2_promptë¥¼ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    segment_paths: list[Path] = []

    # 3. ì²« 8ì´ˆ ì´ë¯¸ì§€â†’ë¹„ë””ì˜¤
    video_1, path_1 = generate_image_to_video(
        prompt=segment_1,
        start_image_path=str(start_image_path),
        end_image_path=None,
        download_name=f"poster_segment_1_{pNo}_8s.mp4",
    )
    if path_1:
        segment_paths.append(path_1)

    # 4. í™•ì¥ 7ì´ˆ
    video_2, path_2 = (None, None)
    if video_1:
        video_2, path_2 = extend_video(
            existing_video=video_1,
            extension_prompt=segment_2,
            duration_s=7,
            download_name=f"poster_segment_2_{pNo}_7s.mp4",
        )
        if path_2:
            segment_paths.append(path_2)

        # NOTE:
    # - ì˜ˆì „ì—ëŠ” segment_1(8s) + segment_2(7s)ë¥¼ ìš°ë¦¬ê°€ FFmpegë¡œ ì´ì–´ë¶™ì˜€ì§€ë§Œ,
    #   ì§€ê¸ˆì€ Veoê°€ ë‘ ë²ˆì§¸ ê²°ê³¼ë¥¼ ì´ë¯¸ "ì™„ì„±ë³¸"ìœ¼ë¡œ ì¤€ë‹¤ê³  ê°€ì •.
    # - ë”°ë¼ì„œ segment_2 ê²°ê³¼(path_2)ë¥¼ ë³¸í¸ìœ¼ë¡œ ì‚¬ìš©í•˜ê³ ,
    #   ê·¸ ì•ì— 2ì´ˆ ì¸íŠ¸ë¡œ(ê²€ì • ë°°ê²½ + ì¶•ì œëª…/ê¸°ê°„)ë¥¼ ë¶™ì¸ë‹¤.

    if not path_2:
        raise RuntimeError("Veo í™•ì¥ ë¹„ë””ì˜¤(segment_2)ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    main_video_path = path_2  # â† Veo ë‘ ë²ˆì§¸ ê²°ê³¼ë¥¼ ìµœì¢… ë³¸í¸ìœ¼ë¡œ ì‚¬ìš©

    # 5. ì¸íŠ¸ë¡œ(ê²€ì • ë°°ê²½ + ì¶•ì œëª…/ê¸°ê°„) 2ì´ˆ ìƒì„± â†’ ë³¸í¸ê³¼ concat

    # 5-1) ë³¸í¸ í•´ìƒë„ ì¶”ì¶œ
    width, height = get_video_resolution(str(main_video_path))
    print(f"ğŸ ë³¸í¸ í•´ìƒë„: {width} x {height}")

    # 5-2) ì¸íŠ¸ë¡œ ì˜ìƒ ìƒì„± (generated_videos í´ë” í•˜ìœ„)
    DOWNLOAD_DIR = Path("generated_videos")
    DOWNLOAD_DIR.mkdir(exist_ok=True)

    intro_output = DOWNLOAD_DIR / f"poster_intro_{pNo}_2s.mp4"
    intro_video_path = create_black_intro_with_text(
        output_video=str(intro_output),
        width=width,
        height=height,
        festival_name_ko=festival_name_ko,
        festival_period_ko=festival_period_ko,
        font_path=str(INTRO_FONT_PATH),
        duration=2.0,
        fps=30,
    )

    # 5-3) ì¸íŠ¸ë¡œ + ë³¸í¸ concat (ì„ì‹œ ìµœì¢…ë³¸)
    final_temp = concat_intro_and_main(
        intro_video=str(intro_video_path),
        main_video=str(main_video_path),
        output_video=str(DOWNLOAD_DIR / f"poster_video_{pNo}_with_intro.mp4"),
    )

    # 6. FRONT public/data/promotion/M000001/{pNo}/video/poster_video.mp4 ë¡œ ì´ë™
    front_root = Path(FRONT_PROJECT_ROOT)
    public_root = front_root / "public"
    rel_dir = Path("data") / "promotion" / PROMOTION_CODE / pNo / "video"
    target_dir = public_root / rel_dir
    target_dir.mkdir(parents=True, exist_ok=True)

    target_path = target_dir / "poster_video.mp4"
    shutil.move(str(final_temp), target_path)
    print(f"âœ… ìµœì¢… í¬ìŠ¤í„° í™ë³´ ì˜ìƒ ì €ì¥: {target_path}")

    db_rel_path = (Path("data") / "promotion" / PROMOTION_CODE / pNo / "video" / "poster_video.mp4").as_posix()

    result: Dict[str, Any] = {
        "db_file_type": "poster_video",
        "type": "video",
        "db_file_path": db_rel_path,
        "type_ko": "í¬ìŠ¤í„° í™ë³´ ì˜ìƒ",
    }

    return result



if __name__ == "__main__":
    """
    ê·¸ëƒ¥ python make_poster_video.py ë¡œ ì‹¤í–‰í–ˆì„ ë•Œ

    - FRONT_PROJECT_ROOT/public/data/promotion/M000001/10/poster/poster_1764222831_0.png
      ì´ í¬ìŠ¤í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ
    - Veo 3.1ë¡œ 15ì´ˆ í¬ìŠ¤í„° í™ë³´ ì˜ìƒ ìƒì„± í›„
    - FRONT_PROJECT_ROOT/public/data/promotion/M000001/10/video/poster_video.mp4 ë¡œ ì €ì¥í•˜ê³ 
    - DBì— ë„£ì„ dict 4ê°œ í•„ë“œë¥¼ ì¶œë ¥í•œë‹¤.
    """

    # í”„ë¡ íŠ¸ public ê¸°ì¤€ ìƒëŒ€ ê²½ë¡œ (ì ˆëŒ€ê²½ë¡œ X)
    test_poster_image_url = "data/promotion/M000001/11/poster/poster_1764405654_3.png"

    try:
        result = run_poster_video_to_editor(
            festival_name_ko="2023 íƒœí™”ê°• êµ­ê°€ì •ì› ë´„ê½ƒì¶•ì œ",
            festival_period_ko="2025.10.25 ~ 2025.10.27",
            festival_location_ko="ìš¸ì‚° íƒœí™”ê°• êµ­ê°€ì •ì›",
            project_id=10,  # pNo = 10
            poster_image_url=test_poster_image_url,
            concept_description="ë´„ê½ƒ, í¬í† ì¡´, ìì—° íë§í˜• ì¶•ì œ",
        )

        print("\nâœ… íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì™„ë£Œ")
        print("ê²°ê³¼ ë°˜í™˜ê°’ (DB ì €ì¥ìš© ë©”íƒ€ë°ì´í„°):")
        print(result)

    except Exception as e:
        print("\nâŒ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:")
        print(repr(e))