"""
OCR -> ClipDrop remove-text íŒŒì´í”„ë¼ì¸ (ë°°ë„ˆ ì—¬ëŸ¬ ì¥ ë°°ì¹˜ ì²˜ë¦¬ ë²„ì „)

í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬:
    pip install paddleocr paddlepaddle==2.5.0
    pip install opencv-python pillow requests python-dotenv

í™˜ê²½ë³€ìˆ˜:
    CLIPDROP_API_KEY=your_api_key_here
"""

import os
from typing import List, Dict, Any
import json
import cv2
import numpy as np
from paddleocr import PaddleOCR
from PIL import Image  # í˜„ì¬ëŠ” ì•ˆ ì“°ì§€ë§Œ, í™•ì¥ìš©ìœ¼ë¡œ ë‚¨ê²¨ë‘ 
import requests
from dotenv import load_dotenv
from pathlib import Path

load_dotenv()
CLIPDROP_API_KEY = os.getenv("CLIPDROP_API_KEY")

# ğŸ”§ ê²½ë¡œ ê¸°ë³¸ê°’ (í•„ìš”í•˜ë©´ ì—¬ê¸°ë§Œ ìˆ˜ì •í•´ì„œ í”„ë¡œì íŠ¸ ê²½ë¡œ ë§ì¶”ë©´ ë¨)
EDITOR_ROOT_DIR = r"C:\final_project\ACC\acc-ai\app\data\editor"
OUTPUT_ROOT_DIR = r"./output_editor"


# ==============================
# 0. OCR ì—”ì§„ ì„¤ì •
# ==============================
OCR_ENGINE = PaddleOCR(
    lang="korean",  # ì˜ì–´ë„ ê°™ì´ ë¨
)


# ==============================
# 1. OCR ê´€ë ¨ ìœ í‹¸
# ==============================
def run_ocr_boxes_only(
    image_path: str,
    min_area: int = 100,
) -> List[Dict[str, Any]]:
    """
    PaddleOCR 3.x .ocr() ê²°ê³¼ì—ì„œ
    í…ìŠ¤íŠ¸ ì˜ì—­ ë°•ìŠ¤(í´ë¦¬ê³¤)ë§Œ ë½‘ì•„ì„œ ë°˜í™˜.

    ë¦¬í„´ ì˜ˆì‹œ:
    [
        {"box": [[x1,y1],[x2,y2],[x3,y3],[x4,y4]], "area": 1234.5},
        ...
    ]
    """
    result_iter = OCR_ENGINE.ocr(image_path)

    boxes: List[Dict[str, Any]] = []
    total_raw = 0

    for res in result_iter:
        # 1) íŒŒì´í”„ë¼ì¸ Result â†’ dict ì¶”ì¶œ
        if hasattr(res, "res"):
            data = res.res
        elif isinstance(res, dict) and "res" in res:
            data = res["res"]
        else:
            data = res

        if not isinstance(data, dict):
            print("[OCR] unexpected result type:", type(data))
            return []

        # 2) í´ë¦¬ê³¤ í›„ë³´: rec_polys > dt_polys > rec_boxes
        polys = data.get("rec_polys") or data.get("dt_polys") or data.get("rec_boxes")
        if polys is None:
            print("[OCR] no polys found, keys:", list(data.keys()))
            return []

        polys = np.array(polys)
        total_raw = polys.shape[0]

        # (N, 8) â†’ (N, 4, 2)
        if polys.ndim == 2 and polys.shape[1] == 8:
            polys = polys.reshape(-1, 4, 2)

        for poly in polys:
            pts = np.array(poly, dtype=np.float32)

            if pts.ndim == 1:
                if pts.size % 2 != 0:
                    continue
                pts = pts.reshape(-1, 2)
            elif pts.ndim == 2 and pts.shape[1] != 2:
                try:
                    pts = pts.reshape(-1, 2)
                except Exception:
                    continue

            if pts.shape[0] < 3:
                continue

            try:
                area = cv2.contourArea(pts)
            except Exception:
                continue

            if area < min_area:
                continue

            boxes.append({"box": pts.tolist(), "area": float(area)})

        # í•œ ì´ë¯¸ì§€ í•œ ë²ˆë§Œ ì²˜ë¦¬
        break

    print(f"[OCR] raw polys: {total_raw}, kept after filters: {len(boxes)}")
    return boxes


def debug_ocr_with_text(
    image_path: str,
    min_score: float = 0.75,
    min_area: int = 500,
) -> List[Dict[str, Any]]:
    """
    í…ìŠ¤íŠ¸ + ì ìˆ˜ + bbox ë””ë²„ê·¸ìš©.
    score >= min_score, area >= min_area ë§Œ ì‚¬ìš©.
    """
    result_iter = OCR_ENGINE.ocr(image_path)

    outputs: List[Dict[str, Any]] = []

    for res in result_iter:
        if hasattr(res, "res"):
            data = res.res
        elif isinstance(res, dict) and "res" in res:
            data = res["res"]
        else:
            data = res

        if not isinstance(data, dict):
            print("[OCR] unexpected result type:", type(data))
            return []

        polys = data.get("rec_polys") or data.get("dt_polys") or data.get("rec_boxes")
        if polys is None:
            print("[OCR] no polys found, keys:", list(data.keys()))
            return []

        polys = np.array(polys)
        if polys.ndim == 2 and polys.shape[1] == 8:
            polys = polys.reshape(-1, 4, 2)

        texts = data.get("rec_texts") or data.get("rec_text") or []
        scores = data.get("rec_scores") or data.get("rec_score") or []

        if isinstance(texts, np.ndarray):
            texts = texts.tolist()
        if isinstance(scores, np.ndarray):
            scores = scores.tolist()

        if not isinstance(texts, (list, tuple)):
            texts = [texts]
        if not isinstance(scores, (list, tuple)):
            scores = [scores] * len(texts)

        n = min(polys.shape[0], len(texts), len(scores))

        for i in range(n):
            poly = polys[i]
            txt = str(texts[i])
            try:
                sc = float(scores[i])
            except Exception:
                sc = 1.0

            if sc < min_score:
                continue

            pts = np.array(poly, dtype=np.float32)
            if pts.ndim == 1 and pts.size % 2 == 0:
                pts = pts.reshape(-1, 2)
            elif pts.ndim == 2 and pts.shape[1] != 2:
                try:
                    pts = pts.reshape(-1, 2)
                except Exception:
                    continue

            if pts.shape[0] < 3:
                continue

            area = cv2.contourArea(pts)
            if area < min_area:
                continue

            x, y, w, h = cv2.boundingRect(pts.astype(np.int32))

            info = {
                "index": len(outputs) + 1,
                "text": txt,
                "score": sc,
                "bbox": [x, y, w, h],
                "poly": pts.tolist(),
            }
            outputs.append(info)

            print(
                f"[{info['index']}] text='{txt}'  "
                f"score={sc:.3f}  bbox(x,y,w,h)={x},{y},{w},{h}"
            )

        break

    print(f"[DEBUG] total detections: {len(outputs)}")
    return outputs


def save_debug_ocr_image(
    image_path: str,
    ocr_boxes: List[Dict[str, Any]],
    output_path: str,
) -> None:
    img = cv2.imread(image_path)
    if img is None:
        raise FileNotFoundError(f"Cannot read image: {image_path}")

    for idx, b in enumerate(ocr_boxes):
        pts = np.array(b["box"], dtype=np.int32)
        cv2.polylines(img, [pts], isClosed=True, color=(0, 0, 255), thickness=3)

        x, y, w, h = cv2.boundingRect(pts)
        cv2.putText(
            img,
            str(idx + 1),
            (x, max(0, y - 10)),
            cv2.FONT_HERSHEY_SIMPLEX,
            1.0,
            (0, 0, 255),
            2,
        )

    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    cv2.imwrite(output_path, img)
    print(f"[DEBUG] OCR box overlay saved to: {output_path}")


def export_ocr_for_gpt(
    image_path: str,
    out_json_path: str,
    min_score: float = 0.75,   # âœ… 0.75 ì´ìƒë§Œ JSONì— ì €ì¥
    min_area: int = 100,
) -> Dict[str, Any]:
    img = cv2.imread(image_path)
    if img is None:
        raise FileNotFoundError(f"Cannot read image: {image_path}")
    h, w = img.shape[:2]

    debug_items = debug_ocr_with_text(
        image_path,
        min_score=min_score,
        min_area=min_area,
    )

    data = {
        "image_size": {"width": w, "height": h},
        "ocr_results": [
            {
                "id": item["index"],
            "text": item["text"],
            "score": float(item["score"]),
            "bbox": item["bbox"],
            }
            for item in debug_items
        ],
    }

    os.makedirs(os.path.dirname(out_json_path), exist_ok=True)
    with open(out_json_path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

    print(f"[EXPORT] OCR for GPT saved to: {out_json_path}")
    return data


# ==============================
# 2. ClipDrop remove-text í˜¸ì¶œ
# ==============================
def call_clipdrop_remove_text(image_path: str, output_image_path: str) -> None:
    if not CLIPDROP_API_KEY:
        raise RuntimeError("CLIPDROP_API_KEY ë¹„ì–´ìˆìŒ")

    url = "https://clipdrop-api.co/remove-text/v1"
    headers = {"x-api-key": CLIPDROP_API_KEY}

    with open(image_path, "rb") as image_file_object:
        files = {
            "image_file": (
                os.path.basename(image_path),
                image_file_object,
                "image/png",
            )
        }

        r = requests.post(url, files=files, headers=headers)

    if r.ok:
        os.makedirs(os.path.dirname(output_image_path), exist_ok=True)
        with open(output_image_path, "wb") as out:
            out.write(r.content)
        print(f"[CLIPDROP] remove-text saved to: {output_image_path}")
    else:
        print("[CLIPDROP ERROR]", r.status_code, r.text)
        r.raise_for_status()


# ==============================
# 3. í•œ ì¥ ì²˜ë¦¬ ìœ ë‹› (type ê¸°ë°˜)
# ==============================
def process_poster(
    image_path: str,
    out_root_for_run: str,
    type_name: str,
) -> Dict[str, str]:
    """
    í•œ ì¥ì˜ í¬ìŠ¤í„°ì— ëŒ€í•´:
      - OCR ë°•ìŠ¤ ë””ë²„ê·¸ ì´ë¯¸ì§€
      - GPTìš© OCR JSON
      - ClipDrop remove-text ê²°ê³¼
    ë¥¼ ìƒì„±í•˜ê³  ê²½ë¡œë“¤ì„ ë¦¬í„´.

    out_root_for_run: output_editor/<run_id> ê°™ì€ ê²½ë¡œ
    type_name: ë©”íƒ€ë°ì´í„°ì˜ "type" (ì˜ˆ: "streetlamp-banner")
    """
    # í´ë” êµ¬ì¡°:
    #   out_root_for_run/
    #       debug/{type}.png
    #       ocr/{type}.json
    #       clean/{type}.png
    debug_dir = os.path.join(out_root_for_run, "debug")
    ocr_dir = os.path.join(out_root_for_run, "ocr")
    clean_dir = os.path.join(out_root_for_run, "clean")

    os.makedirs(debug_dir, exist_ok=True)
    os.makedirs(ocr_dir, exist_ok=True)
    os.makedirs(clean_dir, exist_ok=True)

    debug_overlay_path = os.path.join(debug_dir, f"{type_name}.png")
    ocr_json_path = os.path.join(ocr_dir, f"{type_name}.json")
    cleaned_path = os.path.join(clean_dir, f"{type_name}.png")

    print(f"[STEP 1] Running OCR (boxes only) for type='{type_name}' ...")
    ocr_boxes = run_ocr_boxes_only(image_path)
    print(f"[STEP 1] detected text boxes: {len(ocr_boxes)}")

    # 2) í´ë¦¬ê³¤ ë””ë²„ê·¸ ì´ë¯¸ì§€
    save_debug_ocr_image(image_path, ocr_boxes, debug_overlay_path)

    # 3) GPTìš© JSON (í…ìŠ¤íŠ¸ + bbox)
    export_ocr_for_gpt(image_path, ocr_json_path)

    # 4) í…ìŠ¤íŠ¸ ì œê±° ì´ë¯¸ì§€
    call_clipdrop_remove_text(image_path, cleaned_path)

    return {
        "type": type_name,
        "original": image_path,
        "debug_overlay": debug_overlay_path,
        "ocr_json": ocr_json_path,
        "cleaned": cleaned_path,
    }


# ==============================
# 4. ë°°ì¹˜ ì‹¤í–‰ ì—”íŠ¸ë¦¬ (run_id ë‹¨ìœ„, before_data ê¸°ì¤€)
# ==============================
def run(
    run_id: int,
    editor_root: str = EDITOR_ROOT_DIR,
    output_root: str = OUTPUT_ROOT_DIR,
) -> Dict[str, Dict[str, str]]:
    """
    ì£¼ì–´ì§„ run_idì— ëŒ€í•´:

      - editor/<run_id>/before_data/*.json ì„ ëª¨ë‘ ìˆœíšŒ
      - ê° JSONì—ì„œ:
          - type: "streetlamp-banner"
          - image_path: "C:\\...\\streetlamp_banner_2025....png"
        ë¥¼ ì½ì–´ì˜´
      - image_path ë¥¼ ì‹¤ì œ OCR + remove-text ëŒ€ìƒìœ¼ë¡œ ì‚¬ìš©
      - output_editor/<run_id>/debug/{type}.png
                           /ocr/{type}.json
                           /clean/{type}.png ìƒì„±

    ë¦¬í„´ê°’ (index.json í˜•íƒœ):
      {
        "streetlamp-banner": {
          "type": "streetlamp-banner",
          "original": "C:\\...\\streetlamp_banner_XXXX.png",
          "debug_overlay": "./output_editor/<run_id>/debug/streetlamp-banner.png",
          "ocr_json":      "./output_editor/<run_id>/ocr/streetlamp-banner.json",
          "cleaned":       "./output_editor/<run_id>/clean/streetlamp-banner.png"
        },
        ...
      }
    """
    editor_run_root = os.path.join(editor_root, str(run_id))
    before_data_dir = os.path.join(editor_run_root, "before_data")

    if not os.path.isdir(before_data_dir):
        raise FileNotFoundError(f"before_data dir not found: {before_data_dir}")

    output_run_dir = os.path.join(output_root, str(run_id))
    os.makedirs(output_run_dir, exist_ok=True)

    # before_data/*.json ìˆœíšŒ
    json_files = [
        f for f in os.listdir(before_data_dir)
        if f.lower().endswith(".json")
    ]
    json_files.sort()

    if not json_files:
        print(f"[RUN] no metadata json found in {before_data_dir}")
        return {}

    results: Dict[str, Dict[str, str]] = {}

    for filename in json_files:
        meta_path = os.path.join(before_data_dir, filename)
        stem = Path(filename).stem

        with open(meta_path, "r", encoding="utf-8") as f:
            meta = json.load(f)

        # 1) type ì´ë¦„
        type_name = meta.get("type") or stem

        # 2) ì´ë¯¸ì§€ ê²½ë¡œ
        image_path = meta.get("image_path")
        if not image_path:
            print(f"[WARN] 'image_path' not found in {meta_path}, skip.")
            continue

        # ìƒëŒ€ ê²½ë¡œì¼ ìˆ˜ë„ ìˆìœ¼ë‹ˆ ì ˆëŒ€/ìƒëŒ€ ë‘˜ ë‹¤ ì§€ì›
        if not os.path.isabs(image_path):
            # í”„ë¡œì íŠ¸ êµ¬ì¡°ì— ë§ê²Œ í•„ìš”í•˜ë©´ ì—¬ê¸° ì¡°ì •
            image_path = os.path.abspath(image_path)

        if not os.path.exists(image_path):
            print(f"[WARN] image not found for {type_name}: {image_path}, skip.")
            continue

        print(
            f"\n=== Processing run_id={run_id}, "
            f"type={type_name}, meta_file={filename} ==="
        )

        result_paths = process_poster(
            image_path=image_path,
            out_root_for_run=output_run_dir,
            type_name=type_name,
        )

        # ë©”íƒ€ json ê²½ë¡œë„ ê°™ì´ ê¸°ë¡ (LangChain ìª½ì—ì„œ ì“°ê¸° ì¢‹ê²Œ)
        result_paths["before_data"] = meta_path

        results[type_name] = result_paths

    # index.json ì €ì¥
    index_json_path = os.path.join(output_run_dir, "index.json")
    with open(index_json_path, "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    print(f"\n[RUN] index saved to: {index_json_path}")

    return results


# ==============================
# 5. í…ŒìŠ¤íŠ¸ ì „ìš© main
# ==============================
if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸í•  ë•Œë§Œ ì§ì ‘ í˜¸ì¶œ
    TEST_RUN_ID = 2
    run(TEST_RUN_ID)
