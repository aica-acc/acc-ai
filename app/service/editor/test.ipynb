{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b58a3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "OCR -> MASK 생성 -> ClipDrop Cleanup(Inpainting) 호출 파이프라인\n",
    "\n",
    "필수 라이브러리:\n",
    "    pip install paddleocr paddlepaddle==2.5.0\n",
    "    pip install opencv-python pillow requests python-dotenv\n",
    "\n",
    "환경변수:\n",
    "    CLIPDROP_API_KEY=your_api_key_here\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from typing import List, Dict, Any\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "from paddleocr import PaddleOCR\n",
    "from PIL import Image\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "CLIPDROP_API_KEY = os.getenv(\"CLIPDROP_API_KEY\")\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 0. OCR 엔진 설정\n",
    "# ==============================\n",
    "# 한글+영어 인식\n",
    "OCR_ENGINE = PaddleOCR(\n",
    "    lang=\"korean\",  # 영어도 같이 됨\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a3ef8915",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ocr_boxes_only(\n",
    "    image_path: str,\n",
    "    min_area: int = 100,    # 너무 작은 노이즈 제거용\n",
    ") -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    PaddleOCR 3.x .ocr() 결과에서\n",
    "    텍스트 영역 박스(폴리곤)만 뽑아서 반환.\n",
    "\n",
    "    리턴 예시:\n",
    "    [\n",
    "        {\n",
    "            \"box\": [[x1,y1], [x2,y2], [x3,y3], [x4,y4]],\n",
    "            \"area\": 1234.5,\n",
    "        },\n",
    "        ...\n",
    "    ]\n",
    "    \"\"\"\n",
    "    result_iter = OCR_ENGINE.ocr(image_path)\n",
    "\n",
    "    boxes: List[Dict[str, Any]] = []\n",
    "    total_raw = 0\n",
    "\n",
    "    for res in result_iter:\n",
    "        # 1) 파이프라인 Result → dict 추출\n",
    "        if hasattr(res, \"res\"):\n",
    "            data = res.res\n",
    "        elif isinstance(res, dict) and \"res\" in res:\n",
    "            data = res[\"res\"]\n",
    "        else:\n",
    "            data = res\n",
    "\n",
    "        if not isinstance(data, dict):\n",
    "            print(\"[OCR] unexpected result type:\", type(data))\n",
    "            return []\n",
    "\n",
    "        # 2) 폴리곤 후보: rec_polys > dt_polys > rec_boxes 순으로 사용\n",
    "        polys = data.get(\"rec_polys\", None)\n",
    "        if polys is None:\n",
    "            polys = data.get(\"dt_polys\", None)\n",
    "        if polys is None:\n",
    "            polys = data.get(\"rec_boxes\", None)\n",
    "\n",
    "        if polys is None:\n",
    "            print(\"[OCR] no polys found, keys:\", list(data.keys()))\n",
    "            return []\n",
    "\n",
    "        polys = np.array(polys)\n",
    "        total_raw = polys.shape[0]\n",
    "\n",
    "        # rec_boxes가 (N, 8)일 수도 있으니 (N,4,2)로 reshape\n",
    "        if polys.ndim == 2 and polys.shape[1] == 8:\n",
    "            polys = polys.reshape(-1, 4, 2)\n",
    "\n",
    "        for poly in polys:\n",
    "            pts = np.array(poly, dtype=np.float32)\n",
    "\n",
    "            # 1D로 나오는 경우: [x1,y1,x2,y2,...] → (-1,2)\n",
    "            if pts.ndim == 1:\n",
    "                if pts.size % 2 != 0:\n",
    "                    continue\n",
    "                pts = pts.reshape(-1, 2)\n",
    "\n",
    "            # 2D인데 (N,2)가 아니면 강제로 reshape 시도\n",
    "            elif pts.ndim == 2 and pts.shape[1] != 2:\n",
    "                try:\n",
    "                    pts = pts.reshape(-1, 2)\n",
    "                except Exception:\n",
    "                    continue\n",
    "\n",
    "            if pts.shape[0] < 3:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                area = cv2.contourArea(pts)\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "            if area < min_area:\n",
    "                continue\n",
    "\n",
    "            boxes.append(\n",
    "                {\n",
    "                    \"box\": pts.tolist(),\n",
    "                    \"area\": float(area),\n",
    "                }\n",
    "            )\n",
    "\n",
    "        # 한 이미지 한 번만 처리\n",
    "        break\n",
    "\n",
    "    print(f\"[OCR] raw polys: {total_raw}, kept after filters: {len(boxes)}\")\n",
    "    return boxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "de1823a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_ocr_with_text(\n",
    "    image_path: str,\n",
    "    min_score: float = 0.0,\n",
    "    min_area: int = 0,\n",
    ") -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    PaddleOCR 3.x .ocr() 결과에서\n",
    "    [박스 + 인식 텍스트 + score]를 같이 확인하기 위한 디버그 함수.\n",
    "    콘솔에 한 줄씩 찍어주고, 리스트로도 리턴.\n",
    "\n",
    "    리턴 예시:\n",
    "    [\n",
    "        {\n",
    "            \"index\": 1,\n",
    "            \"text\": \"2025.09.26~\",\n",
    "            \"score\": 0.999,\n",
    "            \"bbox\": [x,y,w,h],\n",
    "            \"poly\": [[x1,y1], ...]\n",
    "        },\n",
    "        ...\n",
    "    ]\n",
    "    \"\"\"\n",
    "    result_iter = OCR_ENGINE.ocr(image_path)\n",
    "\n",
    "    outputs: List[Dict[str, Any]] = []\n",
    "\n",
    "    for res in result_iter:\n",
    "        # 1) res 안에서 실제 데이터 dict 꺼내기\n",
    "        if hasattr(res, \"res\"):\n",
    "            data = res.res\n",
    "        elif isinstance(res, dict) and \"res\" in res:\n",
    "            data = res[\"res\"]\n",
    "        else:\n",
    "            data = res\n",
    "\n",
    "        if not isinstance(data, dict):\n",
    "            print(\"[OCR] unexpected result type:\", type(data))\n",
    "            return []\n",
    "\n",
    "        # 2) 폴리곤(박스) 가져오기\n",
    "        polys = data.get(\"rec_polys\", None)\n",
    "        if polys is None:\n",
    "            polys = data.get(\"dt_polys\", None)\n",
    "        if polys is None:\n",
    "            polys = data.get(\"rec_boxes\", None)\n",
    "        if polys is None:\n",
    "            print(\"[OCR] no polys found, keys:\", list(data.keys()))\n",
    "            return []\n",
    "\n",
    "        polys = np.array(polys)\n",
    "\n",
    "        # (N, 8) → (N, 4, 2) 로 reshape 되는 케이스 처리\n",
    "        if polys.ndim == 2 and polys.shape[1] == 8:\n",
    "            polys = polys.reshape(-1, 4, 2)\n",
    "\n",
    "        # 3) 텍스트 / 스코어 가져오기\n",
    "        texts = data.get(\"rec_texts\", None)\n",
    "        if texts is None:\n",
    "            texts = data.get(\"rec_text\", [])\n",
    "\n",
    "        scores = data.get(\"rec_scores\", None)\n",
    "        if scores is None:\n",
    "            scores = data.get(\"rec_score\", [])\n",
    "\n",
    "        # numpy → list 변환\n",
    "        if isinstance(texts, np.ndarray):\n",
    "            texts = texts.tolist()\n",
    "        if isinstance(scores, np.ndarray):\n",
    "            scores = scores.tolist()\n",
    "\n",
    "        # 스칼라 → 리스트 래핑\n",
    "        if not isinstance(texts, (list, tuple)):\n",
    "            texts = [texts]\n",
    "        if not isinstance(scores, (list, tuple)):\n",
    "            scores = [scores] * len(texts)\n",
    "\n",
    "        n = min(polys.shape[0], len(texts), len(scores))\n",
    "\n",
    "        for i in range(n):\n",
    "            poly = polys[i]\n",
    "            txt = str(texts[i])\n",
    "            try:\n",
    "                sc = float(scores[i])\n",
    "            except Exception:\n",
    "                sc = 1.0\n",
    "\n",
    "            if sc < min_score:\n",
    "                continue\n",
    "\n",
    "            pts = np.array(poly, dtype=np.float32)\n",
    "            if pts.ndim == 1 and pts.size % 2 == 0:\n",
    "                pts = pts.reshape(-1, 2)\n",
    "            elif pts.ndim == 2 and pts.shape[1] != 2:\n",
    "                try:\n",
    "                    pts = pts.reshape(-1, 2)\n",
    "                except Exception:\n",
    "                    continue\n",
    "\n",
    "            if pts.shape[0] < 3:\n",
    "                continue\n",
    "\n",
    "            area = cv2.contourArea(pts)\n",
    "            if area < min_area:\n",
    "                continue\n",
    "\n",
    "            x, y, w, h = cv2.boundingRect(pts.astype(np.int32))\n",
    "\n",
    "            info = {\n",
    "                \"index\": len(outputs) + 1,\n",
    "                \"text\": txt,\n",
    "                \"score\": sc,\n",
    "                \"bbox\": [x, y, w, h],\n",
    "                \"poly\": pts.tolist(),\n",
    "            }\n",
    "            outputs.append(info)\n",
    "\n",
    "            print(\n",
    "                f\"[{info['index']}] text='{txt}'  \"\n",
    "                f\"score={sc:.3f}  bbox(x,y,w,h)={x},{y},{w},{h}\"\n",
    "            )\n",
    "\n",
    "        # 한 이미지 한 번만\n",
    "        break\n",
    "\n",
    "    print(f\"[DEBUG] total detections: {len(outputs)}\")\n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d21e4e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_debug_ocr_image(\n",
    "    image_path: str,\n",
    "    ocr_boxes: List[Dict[str, Any]],\n",
    "    output_path: str,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    OCR 박스들을 원본 이미지 위에 폴리곤(빨간 선)으로 그려서 저장.\n",
    "    \"\"\"\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(f\"Cannot read image: {image_path}\")\n",
    "\n",
    "    for idx, b in enumerate(ocr_boxes):\n",
    "        pts = np.array(b[\"box\"], dtype=np.int32)\n",
    "\n",
    "        # 폴리곤 라인 그대로 그리기\n",
    "        cv2.polylines(img, [pts], isClosed=True, color=(0, 0, 255), thickness=3)\n",
    "\n",
    "        # 번호 라벨\n",
    "        x, y, w, h = cv2.boundingRect(pts)\n",
    "        cv2.putText(\n",
    "            img,\n",
    "            str(idx + 1),\n",
    "            (x, max(0, y - 10)),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            1.0,\n",
    "            (0, 0, 255),\n",
    "            2,\n",
    "        )\n",
    "\n",
    "    cv2.imwrite(output_path, img)\n",
    "    print(f\"[DEBUG] OCR box overlay saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eb204dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_ocr_for_gpt(\n",
    "    image_path: str,\n",
    "    out_json_path: str,\n",
    "    min_score: float = 0.2,\n",
    "    min_area: int = 100,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    GPT에 넘기기 좋은 형식으로 OCR 결과를 JSON으로 저장.\n",
    "\n",
    "    구조 예시:\n",
    "    {\n",
    "      \"image_size\": {\"width\": 4096, \"height\": 1024},\n",
    "      \"ocr_results\": [\n",
    "        {\"id\": 1, \"text\": \"2025.09.26~\", \"score\": 0.999, \"bbox\": [x,y,w,h]},\n",
    "        ...\n",
    "      ]\n",
    "    }\n",
    "    \"\"\"\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(f\"Cannot read image: {image_path}\")\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    debug_items = debug_ocr_with_text(\n",
    "        image_path,\n",
    "        min_score=min_score,\n",
    "        min_area=min_area,\n",
    "    )\n",
    "\n",
    "    data = {\n",
    "        \"image_size\": {\"width\": w, \"height\": h},\n",
    "        \"ocr_results\": [\n",
    "            {\n",
    "                \"id\": item[\"index\"],\n",
    "                \"text\": item[\"text\"],\n",
    "                \"score\": float(item[\"score\"]),\n",
    "                \"bbox\": item[\"bbox\"],\n",
    "            }\n",
    "            for item in debug_items\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    with open(out_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"[EXPORT] OCR for GPT saved to: {out_json_path}\")\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "76663a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_clipdrop_remove_text(image_path: str, output_image_path: str) -> None:\n",
    "    if not CLIPDROP_API_KEY:\n",
    "        raise RuntimeError(\"CLIPDROP_API_KEY 비어있음\")\n",
    "\n",
    "    url = \"https://clipdrop-api.co/remove-text/v1\"\n",
    "    headers = {\"x-api-key\": CLIPDROP_API_KEY}\n",
    "\n",
    "    with open(image_path, \"rb\") as image_file_object:\n",
    "        files = {\n",
    "            \"image_file\": (\n",
    "                os.path.basename(image_path),  # 'image.jpg' 자리\n",
    "                image_file_object,\n",
    "                \"image/png\",                   # test1.png니까 png로\n",
    "            )\n",
    "        }\n",
    "\n",
    "        r = requests.post(url, files=files, headers=headers)\n",
    "\n",
    "    if r.ok:\n",
    "        with open(output_image_path, \"wb\") as out:\n",
    "            out.write(r.content)\n",
    "        print(f\"[CLIPDROP] remove-text saved to: {output_image_path}\")\n",
    "    else:\n",
    "        print(\"[CLIPDROP ERROR]\", r.status_code, r.text)\n",
    "        r.raise_for_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b191f126",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_poster(\n",
    "    image_path: str,\n",
    "    out_dir: str = \"./output\",\n",
    "    prefix: str = \"poster\",\n",
    ") -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    - OCR 폴리곤 검출\n",
    "    - 디버그 오버레이 이미지 생성\n",
    "    - GPT용 OCR JSON 생성\n",
    "    \"\"\"\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    \n",
    "    cleaned_path = os.path.join(out_dir, f\"{prefix}_cleaned.png\")\n",
    "    debug_overlay_path = os.path.join(out_dir, f\"{prefix}_ocr_debug.png\")\n",
    "    ocr_json_path = os.path.join(out_dir, f\"{prefix}_ocr_results.json\")\n",
    "\n",
    "    # 1) 폴리곤만 (레이아웃용)\n",
    "    print(\"[STEP 1] Running OCR (boxes only)...\")\n",
    "    ocr_boxes = run_ocr_boxes_only(image_path)\n",
    "    print(f\"[STEP 1] detected text boxes: {len(ocr_boxes)}\")\n",
    "\n",
    "    # 2) 폴리곤 디버그 이미지\n",
    "    save_debug_ocr_image(image_path, ocr_boxes, debug_overlay_path)\n",
    "\n",
    "    # 3) GPT용 JSON (텍스트+bbox)\n",
    "    export_ocr_for_gpt(image_path, ocr_json_path)\n",
    "\n",
    "     # 3) text 제거 이미지 \n",
    "    call_clipdrop_remove_text(image_path, cleaned_path)\n",
    "\n",
    "    return {\n",
    "        \"original\": image_path,\n",
    "        \"debug_overlay\": debug_overlay_path,\n",
    "        \"ocr_json\": ocr_json_path,\n",
    "        \"cleaned\": cleaned_path,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4ef3ddad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STEP 1] Running OCR (boxes only)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_9400\\4241754748.py:18: DeprecationWarning: Please use `predict` instead.\n",
      "  result_iter = OCR_ENGINE.ocr(image_path)\n",
      "\u001b[33mResized image size (1024x4096) exceeds max_side_limit of 4000. Resizing to fit within limit.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OCR] raw polys: 6, kept after filters: 6\n",
      "[STEP 1] detected text boxes: 6\n",
      "[DEBUG] OCR box overlay saved to: ./output\\sample_ocr_debug.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_9400\\87536550.py:23: DeprecationWarning: Please use `predict` instead.\n",
      "  result_iter = OCR_ENGINE.ocr(image_path)\n",
      "\u001b[33mResized image size (1024x4096) exceeds max_side_limit of 4000. Resizing to fit within limit.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] text='2025.05.03N'  score=0.980  bbox(x,y,w,h)=1586,362,613,148\n",
      "[2] text='2025.05.06'  score=1.000  bbox(x,y,w,h)=2198,392,475,81\n",
      "[3] text='A15B'  score=0.998  bbox(x,y,w,h)=803,455,940,302\n",
      "[4] text='CD'  score=0.988  bbox(x,y,w,h)=1618,470,591,261\n",
      "[5] text='EFGH IJ'  score=0.946  bbox(x,y,w,h)=2200,467,1114,272\n",
      "[6] text='BCD EFG HIJKLM NO'  score=0.955  bbox(x,y,w,h)=753,728,2603,282\n",
      "[DEBUG] total detections: 6\n",
      "[EXPORT] OCR for GPT saved to: ./output\\sample_ocr_results.json\n",
      "[CLIPDROP] remove-text saved to: ./output\\sample_cleaned.png\n",
      "{'original': 'C:\\\\final_project\\\\ACC\\\\acc-ai\\\\app\\\\data\\\\editor\\\\test6.png', 'debug_overlay': './output\\\\sample_ocr_debug.png', 'ocr_json': './output\\\\sample_ocr_results.json', 'cleaned': './output\\\\sample_cleaned.png'}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # 실제 배너 이미지 경로\n",
    "    INPUT_IMAGE = r\"C:\\final_project\\ACC\\acc-ai\\app\\data\\editor\\test6.png\"\n",
    "    \n",
    "\n",
    "    result_paths = process_poster(INPUT_IMAGE, out_dir=\"./output\", prefix=\"sample\")\n",
    "    print(result_paths)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uv-hackathon (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
